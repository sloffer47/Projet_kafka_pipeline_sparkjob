pipeline {
    agent any

    environment {
        EC2_HOST = '13.61.100.227'        // serveur oÃ¹ Docker est installÃ©
        EC2_USER = 'ubuntu'
        APP_NAME = 'Projet_jobspark'
        GITHUB_REPO = 'https://github.com/sloffer47/Projet_kafka_pipeline_sparkjob.git'
        SSH_CREDENTIALS = 'ec2-ssh-key'
        DOCKER_IMAGE = 'jobspark:latest'
    }

    stages {
        stage('ğŸ” Pull Code from GitHub') {
            steps {
                echo 'RÃ©cupÃ©ration du code depuis GitHub...'
                git branch: 'main', url: "${GITHUB_REPO}"
            }
        }

        stage('ğŸ“‹ Verify Files') {
            steps {
                echo 'VÃ©rification des fichiers du projet...'
                sh 'ls -la jobspark/'
                sh 'test -f jobspark/jobspark.py || echo "jobspark.py non trouvÃ©"'
                sh 'test -f jobspark/Dockerfile || echo "Dockerfile non trouvÃ©"'
            }
        }

        stage('ğŸ”‘ Test SSH Connection') {
            steps {
                sshagent([SSH_CREDENTIALS]) {
                    sh 'ssh -o StrictHostKeyChecking=no ${EC2_USER}@${EC2_HOST} "echo âœ… Connexion SSH rÃ©ussie"'
                }
            }
        }

        stage('ğŸš€ Build & Deploy Docker Image') {
            steps {
                sshagent([SSH_CREDENTIALS]) {
                    sh """
                        ssh -o StrictHostKeyChecking=no ${EC2_USER}@${EC2_HOST} '
                            echo "ğŸ§¹ Nettoyage anciens containers..."
                            docker stop ${APP_NAME} 2>/dev/null || true
                            docker rm ${APP_NAME} 2>/dev/null || true
                            docker rmi ${DOCKER_IMAGE} 2>/dev/null || true

                            echo "ğŸ”¨ Construction image Docker jobspark..."
                            cd ~/ && git clone -b main ${GITHUB_REPO} temp_jobspark || (cd temp_jobspark && git pull)
                            cd temp_jobspark/jobspark
                            docker build -t ${DOCKER_IMAGE} .

                            echo "ğŸš€ Lancement du container Spark Job..."
                            docker run -d --name ${APP_NAME} ${DOCKER_IMAGE}
                            
                            echo "âœ… Container lancÃ© avec succÃ¨s"
                        '
                    """
                }
            }
        }

        stage('ğŸ“œ Logs & Validation') {
            steps {
                sshagent([SSH_CREDENTIALS]) {
                    sh """
                        ssh -o StrictHostKeyChecking=no ${EC2_USER}@${EC2_HOST} '
                            echo "ğŸ“ Suivi des logs jobspark..."
                            docker logs -f ${APP_NAME}
                        '
                    """
                }
            }
        }

        stage('âš¡ Option: ExÃ©cution manuelle Spark') {
            steps {
                echo '''
                Pour exÃ©cuter manuellement depuis le container jobspark :
                docker exec -it ${APP_NAME} /bin/bash
                spark-submit --master spark://spark:7077 --packages org.apache.spark:spark-sql-kafka-0-10_2.12 jobspark.py
                '''
            }
        }
    }

    post {
        success {
            echo '''
            ğŸ‰ DÃ‰PLOIEMENT JOBSPARK RÃ‰USSI!
            ğŸ“Š Container en cours d'exÃ©cution : docker ps | grep ${APP_NAME}
            ğŸ“ Suivi des logs : docker logs ${APP_NAME}
            '''
        }
        failure {
            echo '''
            âŒ Ã‰CHEC DU DÃ‰PLOIEMENT JOBSPARK
            ğŸ” VÃ©rifiez les logs et l'Ã©tat Docker sur le serveur
            '''
        }
    }
}
